{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "quarter_height, quarter_width = height/4, width/4\n",
    "\n",
    "T = np.float32([[1, 0, quarter_width], [0, 1, quarter_height]])\n",
    "\n",
    "img_translation = cv2.warpAffine(image, T, (width, height))\n",
    "cv2.imshow('Translation', img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), 45, 1)\n",
    "\n",
    "img_translation = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "img_translation = cv2.transpose(img_translation)\n",
    "cv2.imshow('Translation', img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('test.jpg')\n",
    "print(image.shape)\n",
    "cv2.imshow('Original',image)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_scaled = cv2.resize(image, None, fx = 0.5, fy = 0.5)\n",
    "cv2.imshow('Translation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_scaled = cv2.resize(image, None, fx = 2, fy = 2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Translation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_scaled = cv2.resize(image, (300, 400), cv2.INTER_AREA)\n",
    "cv2.imshow('Translation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_scaled = cv2.resize(image, (500, 600), cv2.INTER_LANCZOS4)\n",
    "cv2.imshow('Translation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Using image pyramids\n",
    "\n",
    "smaller = cv2.pyrDown(image)\n",
    "cv2.imshow('Translation', smaller)\n",
    "cv2.waitKey()\n",
    "\n",
    "larger = cv2.pyrUp(image)\n",
    "cv2.imshow('Translation', larger)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 408\n",
      "20 122\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('./Test_Images/profile.jpg')\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "print(height, width)\n",
    "start_row, start_col = int(height * .05), int(width * .30)\n",
    "print(start_row, start_col)\n",
    "end_row, end_col = int(height * .70), int(width * .90)\n",
    "\n",
    "cropped = image[start_row:end_row, start_col:end_col]\n",
    "\n",
    "cv2.imshow('Cropped Image',cropped)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "M = np.ones(image.shape, dtype = 'uint8') * 75\n",
    "\n",
    "added = cv2.add(image, M)\n",
    "subtracted = cv2.subtract(image, M)\n",
    "\n",
    "cv2.imshow('Added', added)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('Subtracted', subtracted)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitwise operations and Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "square = np.ones((300, 300), np.uint8)\n",
    "cv2.rectangle(square, (50, 50), (250, 250), 255, -2)\n",
    "cv2.imshow('Square', square)\n",
    "cv2.waitKey()\n",
    "\n",
    "ellipse = np.ones((300, 300), np.uint8)\n",
    "cv2.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\n",
    "cv2.imshow('Ellipse', ellipse)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "And = cv2.bitwise_and(square, ellipse)\n",
    "cv2.imshow('AND', And)\n",
    "cv2.waitKey()\n",
    "\n",
    "bitwise_or = cv2.bitwise_or(square, ellipse)\n",
    "cv2.imshow('OR', bitwise_or)\n",
    "cv2.waitKey()\n",
    "\n",
    "bitwise_xor = cv2.bitwise_xor(square, ellipse)\n",
    "cv2.imshow('XOR', bitwise_xor)\n",
    "cv2.waitKey()\n",
    "\n",
    "Not = cv2.bitwise_not(square)\n",
    "cv2.imshow('NOT-square', Not)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('./Test_Images/profile.jpg')\n",
    "\n",
    "kernel_sharpening = np.array([[-1, -1, -1],\n",
    "                     [-1, 9, -1],\n",
    "                     [-1, -1, -1]])\n",
    "\n",
    "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "cv2.imshow('Sharpened', sharpened)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "ret, thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary 1', thresh1)\n",
    "cv2.waitKey()\n",
    "\n",
    "ret, thresh2 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Threshold Binary 2', thresh2)\n",
    "cv2.waitKey()\n",
    "\n",
    "ret, thresh3 = cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)\n",
    "cv2.imshow('Threshold Binary 3', thresh3)\n",
    "cv2.waitKey()\n",
    "\n",
    "ret, thresh4 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)\n",
    "cv2.imshow('Threshold Binary 4', thresh4)\n",
    "cv2.waitKey()\n",
    "\n",
    "ret, thresh5 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('Threshold Binary 5', thresh5)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('test.jpg')\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "\"\"\"thresh = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "cv2.imshow('Adaptive Gaussian Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\n",
    "_,thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow('Adaptive OTSU Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\n",
    "_,thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Adaptive OTSU Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\n",
    "_,thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "cv2.imshow('Adaptive OTSU Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\"\"\"\n",
    "_,thresh = cv2.threshold(image, 250, 255, cv2.THRESH_OTSU)\n",
    "cv2.imshow('Adaptive OTSU Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilation, Erosion, Closing, Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('simpleform.jpg')\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "kernel = np.ones((4,4), np.uint8)\n",
    "\n",
    "# Removes pixels to the boundaries of object\n",
    "erosion = cv2.erode(image, kernel, iterations = 1)\n",
    "cv2.imshow('Erosion', erosion)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Adds pixels to the boundaries of object\n",
    "dilation = cv2.dilate(image, (6, 6), iterations = 1)\n",
    "cv2.imshow('Erosion', dilation)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Erosion the dilation\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Opening', opening)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Dilation then Erosion\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('Closing', closing)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg',0)\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "height, width = image.shape\n",
    "\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize = 5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize = 5)\n",
    "\n",
    "cv2.imshow('Sobel_X', sobel_x)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('Sobel_Y', sobel_y)\n",
    "cv2.waitKey()\n",
    "\n",
    "sobel_or = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "cv2.imshow('Sobel_X_and_Y', sobel_or)\n",
    "cv2.waitKey()\n",
    "\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "cv2.imshow('Laplacian', laplacian)\n",
    "cv2.waitKey()\n",
    "\n",
    "canny = cv2.Canny(image, 20, 170)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Image with shapes\n",
    "image = cv2.imread('shapes1.png')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "# Find Canny Edges\n",
    "edges = cv2.Canny(gray_blur, 30, 200)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find Contours\n",
    "_, contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Edges after contouring', edges)\n",
    "cv2.waitKey()\n",
    "\n",
    "print('Number of Contours found = ' + str(len(contours)))\n",
    "\n",
    "#contours = np.array(contours).reshape((-1,1,2)).astype(np.int32)\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 2)\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sorting Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Image with shapes\n",
    "image = cv2.imread('shapes1.png')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "\n",
    "original_image = image\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "edges = cv2.Canny(gray_blur, 30, 200)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find Contours\n",
    "_, contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Edges after contouring', edges)\n",
    "cv2.waitKey()\n",
    "\n",
    "print('Number of Contours found = ' + str(len(contours)))\n",
    "\n",
    "#contours = np.array(contours).reshape((-1,1,2)).astype(np.int32)\n",
    "cv2.drawContours(blank_image, contours, -1, (0,255,0), 2)\n",
    "cv2.imshow('Contours on Blank Image', blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 2)\n",
    "cv2.imshow('Contours on Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Contours by Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to display area\n",
    "def contour_areas(contours):\n",
    "    # returns areas of all contours in a list\n",
    "    all_areas = []\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    \n",
    "    return all_areas\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('shapes1.png')\n",
    "original_image = image\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "edges = cv2.Canny(gray_blur, 30, 200)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find Contours\n",
    "_, contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Edges after contouring', edges)\n",
    "cv2.waitKey()\n",
    "print(contours[1])\n",
    "print('Contour Areas before Sorting')\n",
    "print(contour_areas(contours))\n",
    "\n",
    "# Sort Contours large to small\n",
    "sorted_contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\n",
    "print('Contour Areas after Sorting')\n",
    "print(contour_areas(sorted_contours))\n",
    "\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(original_image, [c], -1, (255, 0, 0), 2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('Contours by Area', original_image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Left to Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to sort left to right\n",
    "def x_cord_contour(contours):\n",
    "    \n",
    "    if cv2.contourArea(contours) > 5:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "\n",
    "def label_contour_center(image, c):\n",
    "    \n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    \n",
    "    cv2.circle(image, (cx, cy), 10, (0,125,255), -1)\n",
    "    return image\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('square-shape-activity-2.jpg')\n",
    "original_image = image.copy()\n",
    "\n",
    "for (i, c) in enumerate(contours):\n",
    "    original_image = label_contour_center(image, c)\n",
    "    \n",
    "cv2.imshow(\"Contour centres\", image)\n",
    "cv2.waitKey(0)\n",
    "# Sort by left to right\n",
    "contours_left_to_right = sorted(contours, key = x_cord_contour, reverse = False)\n",
    "\n",
    "for (i, c) in enumerate(contours_left_to_right):\n",
    "    cv2.drawContours(original_image, [c], -1, (0, 0, 255), 3)\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    cv2.putText(original_image, str(i+1), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('Left to Right Contours', original_image)\n",
    "    cv2.waitKey(0)\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    \n",
    "    # Cropping and saving each contour\n",
    "    croppped_contour = original_image[y:y + h, x:x + w]\n",
    "    image_name = \"output_shape_\" + str(i + 1) + \".jpg\"\n",
    "    print(image_name)\n",
    "    cv2.imwrite(image_name, croppped_contour)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Shape Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template = cv2.imread('A4-4x.png',0)\n",
    "cv2.imshow('Original', template)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "target = cv2.imread('A4 Copy 2x.png')\n",
    "target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh1 = cv2.threshold(template, 127, 255, 0)\n",
    "ret, thresh1 = cv2.threshold(target_gray, 127, 255, 0)\n",
    "\n",
    "ret, contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "sorted_contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\n",
    "template_contour = contours[1]\n",
    "\n",
    "ret, contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    \n",
    "    match = cv2.matchShapes(template_contour, c, 1, 0.0)\n",
    "    print(match)\n",
    "    if match < 0.15:\n",
    "        closest_contour = c\n",
    "    else:\n",
    "        closest_contour = []\n",
    "            \n",
    "cv2.drawContours(target, [closest_contour], -1, (0, 255, 0), 3)\n",
    "cv2.imshow('Output', target)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4964, 3508, 3)\n",
      "(993, 702, 3)\n",
      "(345, 2721)\n",
      "(69, 544)\n",
      "-1573427.0 36538888.0 (62, 816) (77, 48)\n",
      "Result [-1573427.0, 36538888.0, (62, 816), (77, 48)]\n",
      "x = 77, y  = 48 width = 544 height = 69\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input image\n",
    "image = cv2.imread('img_2.jpg')\n",
    "print(image.shape)\n",
    "imagecopy = image.copy()\n",
    "image = cv2.resize(image, None, fx = 0.2, fy = 0.2)\n",
    "print(image.shape)\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Template image\n",
    "template = cv2.imread('template1.jpg',0)\n",
    "print(template.shape)\n",
    "template = cv2.resize(template, None, fx = 0.2, fy = 0.2)\n",
    "print(template.shape)\n",
    "cv2.imshow('Template', template)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "height = template.shape[0]\n",
    "width = template.shape[1]\n",
    "\n",
    "result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF)\n",
    "#print(result)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "print(min_val, max_val, min_loc, max_loc)\n",
    "print('Result',[min_val, max_val, min_loc, max_loc])\n",
    "# Create bounding box\n",
    "top_left = max_loc\n",
    "print('x = ' + str(max_loc[0]) + \", y  = \" + str(max_loc[1]) + ' width = ' + str(width) + ' height = ' + str(height))\n",
    "bottom_right = (top_left[0] + width, top_left[1] + height)\n",
    "#top_left[0] = float(top_left[0]) * 1.2\n",
    "#top_left[1] = float(top_left[1]) * 1.2\n",
    "top_left1 = (int(float(top_left[0]) / 0.2), int(float(top_left[1]) / 0.2))\n",
    "#bottom_right[0] = float(bottom_right[0]) * 1.2\n",
    "#bottom_right[1] = float(bottom_right[1]) * 1.2\n",
    "bottom_right1 = (int(float(bottom_right[0]) / 0.2), int(float(bottom_right[1]) / 0.2))\n",
    "cv2.rectangle(imagecopy, top_left1, bottom_right1, (0,255,0), 1)\n",
    "cv2.rectangle(image, top_left, bottom_right, (0,255,0), 1)\n",
    "# 1: x = 77, y= 48, width = 544, height = 69\n",
    "# 2: x = 85, y  = 187 width = 554 height = 62\n",
    "# 3: x = 72, y  = 514 width = 588 height = 64\n",
    "# x = 77, y  = 48 width = 544 height = 69\n",
    "# x = 385, y  = 238 width = 2721 height = 345\n",
    "cv2.imshow('Here is the match', imagecopy)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Here is the match', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "filled_image = 'filled.jpg'\n",
    "nonfilled_image = 'nonfilled.jpg'\n",
    "\n",
    "cropped = [[77,48,544,69],[85,187,554,62],[72,514,588,64]]\n",
    "def wordDetection(line):\n",
    "    kernel = np.ones((10, 15), np.uint8)\n",
    "    img_dilation = cv2.dilate(line, kernel, iterations=1)\n",
    "    #cv2.imshow('orig', img_dilation)\n",
    "    #cv2.waitKey(0)\n",
    "    im2, ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    word_list = []\n",
    "    for i, ctr in enumerate(sorted_ctrs):\n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        # Getting ROI\n",
    "        roi = line[y:y + h, x:x + w]\n",
    "        characters = characterDetection(roi)\n",
    "        word_list.append(\"\".join(characters))\n",
    "        # cv2.imshow('test', roi)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "        #cv2.imwrite('test' + str(i) + '.jpg', roi)\n",
    "        #new_image = cv2.imread('test' + str(i) + '.jpg')\n",
    "        #gray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
    "        #ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        #kernel = np.ones((10, 1), np.uint8)\n",
    "        #img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "        #cv2.imshow('dilation', img_dilation)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        #im2, ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        #e = thresh.copy()\n",
    "        #sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "        #character_list = []\n",
    "    print(\" \".join(word_list))\n",
    "        \n",
    "def makeSquare(not_square):\n",
    "    # Adds black pixels as padding\n",
    "    \n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2 * width, 2 * height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        if (height > width):\n",
    "            pad = (height - width)/2\n",
    "            pad = int(pad)\n",
    "            #doublesize = int(doublesize)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad,\\\n",
    "                                                  pad, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "        else:\n",
    "            pad = (width - height)/2\n",
    "            pad = int(pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0,\\\n",
    "                                                  cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    return doublesize_square\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions)/squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    widht_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    if (height_r < widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    return ReSizedImg\n",
    "    \n",
    "def characterDetection(word):\n",
    "    kernel = np.ones((10, 1), np.uint8)\n",
    "    img_dilation = cv2.dilate(word, kernel, iterations=1)\n",
    "    im2, ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    character_list = []\n",
    "    for i, ctr in enumerate(sorted_ctrs):\n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        #dimensions = [x, y, w, h]\n",
    "        # Getting ROI\n",
    "        roi = word[y:y + h, x:x + w]\n",
    "        squared = makeSquare(roi)\n",
    "        final = resize_to_pixel(28, squared)\n",
    "        letter = characterPrediction(final)\n",
    "        character_list.append(letter)\n",
    "    return character_list\n",
    "    \n",
    "def characterPrediction(character):\n",
    "    predict_img = im.img_to_array(character)\n",
    "    predict_img = np.expand_dims(predict_img, axis = 0)\n",
    "    result = model.predict_classes(predict_img)\n",
    "    print(result)\n",
    "    dictionary = {}\n",
    "    index = 0\n",
    "    for probab in result[0]:\n",
    "        dictionary[index] = probab\n",
    "        index += 1\n",
    "    key_max = max(dictionary.keys(), key=(lambda k: dictionary[k]))\n",
    "    charac = label_dictionary[key_max]\n",
    "    return(charac)\n",
    "\n",
    "for x, y, w, h in cropped:\n",
    "    # predict content from nonfilled\n",
    "    nonfilled = cv2.imread(nonfilled_image)\n",
    "    filled = cv2.imread(filled_image)\n",
    "    nonfilled_copy = nonfilled.copy()\n",
    "    filled_copy = filled.copy()\n",
    "    # crop into image for template matching\n",
    "    nonfilled_crop = nonfilled_copy[y:y + h, x:x + w]\n",
    "    cv2.imshow('filled',nonfilled_crop)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    #wordDetection(nonfilled_crop)\n",
    "    # set difference\n",
    "    filled_copy = cv2.cvtColor(filled_copy,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.cvtColor(nonfilled_crop,cv2.COLOR_BGR2GRAY)\n",
    "    result = cv2.matchTemplate(filled_copy, gray, cv2.TM_CCOEFF)\n",
    "    #print(result)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "    #print(min_val, max_val, min_loc, max_loc)\n",
    "    #print('Result',[min_val, max_val, min_loc, max_loc])\n",
    "    # Create bounding box\n",
    "    top_left = max_loc\n",
    "    #print('x = ' + str(max_loc[0]) + \", y  = \" + str(max_loc[1]) + ' width = ' + str(width) + ' height = ' + str(height))\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    newcrop = filled_copy[top_left[1]:top_left[1] + h, top_left[0]:top_left[0] + w]\n",
    "    cv2.imshow('filled',newcrop)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    nonfilled_crop = cv2.cvtColor(nonfilled_crop,cv2.COLOR_BGR2GRAY)\n",
    "    #newcrop = cv2.cvtColor(newcrop,cv2.COLOR_BGR2GRAY)\n",
    "    nonfilled_crop = np.array(nonfilled_crop)\n",
    "    newcrop = np.array(newcrop)\n",
    "    nonfilled_crop = cv2.threshold(nonfilled_crop, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    newcrop = cv2.threshold(newcrop, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    difference = np.subtract(newcrop, nonfilled_crop)\n",
    "    #cv2.rectangle(filled, top_left, bottom_right, (0,255,0), 1)\n",
    "    # predict content from differenced image\n",
    "    cv2.imshow('filled',nonfilled_crop)\n",
    "    cv2.imshow('filled',newcrop)\n",
    "    cv2.imshow('filled',difference)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTags(non_filled_image, coordinates):\n",
    "    non_filled_image = cv2.imread(non_filled_image, 0)\n",
    "    non_filled_image = cv2.threshold(non_filled_image, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    tags = []\n",
    "    for x, y, w, h in coordinates:\n",
    "        cropped = non_filled_image[y:y + h, x:x + w]\n",
    "        word = wordDetection(cropped)\n",
    "        tags.append(word)\n",
    "    return tags\n",
    "\n",
    "def preprocess(filled_image, non_filled_image, coordinates):\n",
    "    non_filled_image = cv2.imread(non_filled_image, 0)\n",
    "    non_filled_image = cv2.threshold(non_filled_image, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    filled_image = cv2.imread(filled_image, 0)\n",
    "    filled_image = cv2.threshold(filled_image, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    text = []\n",
    "    for x, y, w, h in coordinates:\n",
    "        cropped = non_filled_image[y:y + h, x:x + w]\n",
    "        xnew, ynew, wnew, hnew = matchTemplate(cropped, filled_image)\n",
    "        cropped_new = filled_image[ynew:ynew + h,xnew:xnew + w]\n",
    "        handwritten_image = setDifference(cropped_new, cropped)\n",
    "        word = wordDetection(handwritten_image)\n",
    "        text.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "form = cv2.imread('img_2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "form = cv2.resize(form, (600, 800))\n",
    "form = np.array(form)\n",
    "#form = cv2.GaussianBlur(form, (5,5), 0)\n",
    "form = cv2.threshold(form, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "cv2.imshow('Form', form)\n",
    "cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "fill_form = cv2.imread('img_2copy.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "fill_form = cv2.resize(fill_form, (600, 800))\n",
    "fill_form = np.array(fill_form)\n",
    "#fill_form = cv2.GaussianBlur(fill_form, (5,5), 0)\n",
    "fill_form = cv2.threshold(\n",
    "    fill_form, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "cv2.imshow('Filled Form', fill_form)\n",
    "cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "result = np.subtract(fill_form, form)\n",
    "cv2.imshow('Result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input image\n",
    "image = cv2.imread('./Test_Images/img_0.jpg')\n",
    "image = cv2.resize(image, (700,1000))\n",
    "print(image.shape)\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "topleft = (232,307)\n",
    "x = 232\n",
    "y = 307\n",
    "#print(topleft)\n",
    "#print(t)\n",
    "bottom_right = (x + 52, y + 121)\n",
    "cv2.rectangle(image, topleft, bottom_right, (0,255,0), 5)\n",
    "cv2.imshow('Here is the match', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oriented FAST and Rotated BRIEF (ORB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('shapes.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "orb = cv2.ORB(1000)\n",
    "\n",
    "keypoints = orb.detect(gray, None)\n",
    "\n",
    "keypoints, descriptors = orb.compute(gray, keypoints)\n",
    "print(\"Number of keypoints detected = \",len(keypoints))\n",
    "\n",
    "image = cv2.drawKeypoints(image, keypoints, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('Feature Method - ORB', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Analysis using Dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "class TooManyFaces(Exception):\n",
    "    pass\n",
    "\n",
    "class NoFaces(Exception):\n",
    "    pass\n",
    "\n",
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    if len(rects) > 1:\n",
    "        raise TooManyFaces\n",
    "    if len(rects) == 0:\n",
    "        raise NoFaces\n",
    "        \n",
    "    return np.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "def annotate_landmarks(im, landmarks):\n",
    "    im = im.copy()\n",
    "    \n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im, str(idx), pos, fontFace = cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale = 0.4, color = (0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color = (0, 255, 255))\n",
    "        \n",
    "    return im\n",
    "\n",
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "landmarks = get_landmarks(image)\n",
    "image_with_landmarks = annotate_landmarks(image, landmarks)\n",
    "\n",
    "cv2.imshow('Image with Landmarks',image_with_landmarks)\n",
    "cv2.imwrite('image_with_landmarks.jpg',image_with_landmarks)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('square-shape-activity-2.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, 1)\n",
    "\n",
    "ret, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours:\n",
    "    \n",
    "    approx = cv2.approxPolyDP(cnt, 0.01 * cv2.arcLength(cnt, True), True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        \n",
    "        if abs(w-h) <= 3:\n",
    "            shape_name = \"Square\"\n",
    "            \n",
    "            cv2.drawContours(image, [cnt], 0, (0, 125, 125), -1)\n",
    "            cv2.putText(image, shape_name, (cx - 5, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "    cv2.imshow('Identifying images',image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from imutils import contours\n",
    "import imutils\n",
    "\n",
    "# Function to sort left to right\n",
    "def x_cord_contour(cnts):\n",
    "    \n",
    "    if cv2.contourArea(cnts) > 5:\n",
    "        M = cv2.moments(cnts)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "    \n",
    "def makeSquare(not_square):\n",
    "    # Adds black pixels as padding\n",
    "    \n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2 * width, 2 * height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        if (height > width):\n",
    "            pad = (height - width)/2\n",
    "            pad = int(pad)\n",
    "            #doublesize = int(doublesize)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad,\\\n",
    "                                                  pad, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "        else:\n",
    "            pad = (width - height)/2\n",
    "            pad = int(pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0,\\\n",
    "                                                  cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    return doublesize_square\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions)/squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    widht_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    if (height_r < widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    return ReSizedImg\n",
    "\n",
    "image = cv2.imread('img045-00691.png')\n",
    "cv2.imshow('Original', image)\n",
    "#img_scaled = cv2.resize(image, None, fx = 0.36, fy = 0.36)\n",
    "#cv2.imshow('Translation', image)\n",
    "cv2.waitKey()\n",
    "blurred = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Gray', blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Blur image then find edges using Canny\n",
    "\"\"\"blurred = cv2.GaussianBlur(blurred, (5, 5), 0)\n",
    "cv2.imshow('Blurred', blurred)\n",
    "cv2.waitKey(0)\"\"\"\n",
    "\n",
    "ret, regoi = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('ROI',regoi)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "cv2.imshow('Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# dilation\n",
    "kernel = np.ones((30, 10), np.uint8)\n",
    "# original values 5,100\n",
    "img_dilation = cv2.dilate(regoi, kernel, iterations=4)\n",
    "cv2.imshow('dilated', img_dilation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#lines = cv2.HoughLinesP(edged, 1, np.pi / 180, 300, 5, 5)\n",
    "#print(lines.shape)\n",
    "\n",
    "#for x1, y1, x2, y2 in lines[0]:\n",
    "   # cv2.line(image, (x1, y1), (x2, y2), (255, 255, 255), 3)\n",
    "    \n",
    "# cv2.imshow('lines', image)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Find contours\n",
    "ret, cnts, hierarchy = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort out contours left to right by using their x coordinates\n",
    "#contours = sorted(contours, key = x_cord_contour(contours), reverse = False)\n",
    "\n",
    "\n",
    "(cnts, boundingBoxes) = contours.sort_contours(cnts, method=\"top-to-bottom\")\n",
    "clone = image.copy()\n",
    "\n",
    "\n",
    "\n",
    "# Loop over the contours\n",
    "# for (i, c) in enumerate(contours)\n",
    "# for c in contours:\n",
    "a = 0\n",
    "for c in cnts:\n",
    "    # computing bounding box for rectangle\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    \n",
    "    if w >=17 and h >=17:\n",
    "        roi = blurred[y:y +h, x:x + w]\n",
    "        ret, roi = cv2.threshold(roi, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "        # roi = int(roi)\n",
    "        squared = makeSquare(roi)\n",
    "        final = resize_to_pixel(28, squared)\n",
    "        l = str(a)\n",
    "        cv2.imshow(\"final\", final)\n",
    "        cv2.imwrite(\"img_\"+l+\".jpg\",final)\n",
    "        a= a + 1\n",
    "        cv2.waitKey(0)\n",
    "print(a)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def makeSquare(not_square):\n",
    "    # Adds black pixels as padding\n",
    "    \n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2 * width, 2 * height), interpolation = cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        if (height > width):\n",
    "            pad = (height - width)/2\n",
    "            pad = int(pad)\n",
    "            #doublesize = int(doublesize)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad,\\\n",
    "                                                  pad, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "        else:\n",
    "            pad = (width - height)/2\n",
    "            pad = int(pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0,\\\n",
    "                                                  cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    return doublesize_square\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    \n",
    "    buffer_pix = 4\n",
    "    dimensions = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions)/squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    widht_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    if (height_r < widht_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    return ReSizedImg\n",
    "\n",
    "img = cv2.imread('test.png')\n",
    "resized = cv2.resize(img, None,fx=0.6, fy=0.6, interpolation = cv2.INTER_CUBIC)\n",
    "gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "cv2.imshow('Thresh', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "thresh.shape\n",
    "\n",
    "#squared = makeSquare(thresh)\n",
    "final = resize_to_pixel(28, thresh)\n",
    "cv2.imshow('final',final)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "a = cv2.imread('a.png')\n",
    "a_array = image.img_to_array(a)\n",
    "print(a_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"abcd.txt\",\"w\") as text_file:\n",
    "    text_file.write(str(a_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD1CAYAAABA+A6aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBIEOAEEQ6AAQBIEOAEH8H2MRUQP5uHoSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x145b44d8ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mse(imageA, imageB):\n",
    "\t# the 'Mean Squared Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\t\n",
    "\t# return the MSE, the lower the error, the more \"similar\"\n",
    "\t# the two images are\n",
    "\treturn err\n",
    " \n",
    "def compare_images(imageA, imageB, title):\n",
    "\t# compute the mean squared error and structural similarity\n",
    "\t# index for the images\n",
    "\tm = mse(imageA, imageB)\n",
    "\ts = ssim(imageA, imageB)\n",
    "\tprint(int(m))\n",
    "\t# setup the figure\n",
    "\tfig = plt.figure(title)\n",
    "\tplt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "    \n",
    "\t# show first image\n",
    "\tax = fig.add_subplot(1, 2, 1)\n",
    "\tplt.imshow(imageA, cmap = plt.cm.gray)\n",
    "\tplt.axis(\"off\")\n",
    " \n",
    "\t# show the second image\n",
    "\tax = fig.add_subplot(1, 2, 2)\n",
    "\tplt.imshow(imageB, cmap = plt.cm.gray)\n",
    "\tplt.axis(\"off\")\n",
    " \n",
    "\t# show the images\n",
    "\tplt.show()\n",
    "    \n",
    "a = cv2.imread('1871_cnt_1.jpg')\n",
    "b = cv2.imread('1924_cnt_1.jpg')\n",
    "a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "b = cv2.cvtColor(b, cv2.COLOR_BGR2GRAY)\n",
    "#ret, thresh1 = cv2.threshold(a, 120, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "#cv2.imshow('thresh1',thresh1)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "#ret, thresh2 = cv2.threshold(b, 120, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    \n",
    "m = compare_images(a, b, \"Original vs. Original\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAD8CAYAAAAsX4y/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAABTxJREFUeJzt3Ntq40oQQFHrkP//ZZ2HYRhmbCeW\nvXXttR5zQwSyKapbmeZ5vgHQ+W/vBwC4GmEFiAkrQExYAWLCChATVoCYsALEhBUgJqwAsa+9H+B2\nu92mafL6F7CreZ6n6meZWAFiwgoQE1aAmLACxIQVICasADFhBYgJK0BMWAFiwgoQE1aAmLACxIQV\nICasADFhBYgJK0BMWAFiwgoQE1aAmLACxIQVICasADFhBYgJK0BMWAFiwgoQE1aAmLACxIQVICas\nADFhBYgJK0BMWAFiwgoQE1aAmLACxIQVICasADFhBYgJK0BMWAFiwgoQE1aAmLACxIQVICasALGv\nvR+AMc3zfPexaZp2eBLoCSubehTUfz8nsJydsLKJ74L67GsFlrOyY2V1S6JafB/szcTKaoSRUZlY\nWUUVVXHmjISVnBgyOmElJaogrITWiqpYczbCSkL84A9h5WOiCn8TVj4iqnBPWHmbqMJjwspbRBWe\nE1YW2zqq/mcAZ+OVVl5mSoXXmFh5iajC64SVH4kqLCOsfEtUYTlh5SlRhfcIKw+JKrxPWLlzpKi6\nasUZCSt/OVJU4azcY+V2uwkqlEysiCrEhHVwogo9YR2YqMI6hHVQa0e1OM13I4CzEtYBnSGqcGbC\nOpitomrNwMiElYxJFX5xj3Uga02RawRVpDkzEysfEUC4J6y87VlU7VcZnbDyFpMqPCesLLZ2VEWb\nsxNWFhE9+JmwDuTTKIoqvEZYB/NuHF/9PgdXIKxDWhLXaZo2nVRNxVyBsA7qlYCJHLzHm1cDe/Ze\nv6DCZ4SVLKT2q/CLVQBATFg5DCsIrkJYAWLCSsJ+Ff4QVoCYsALEhJVDcHDFlQgrH7Nfhb8JK0BM\nWAFiwsru7Fe5GmHlI/arcE9YAWLCyq6sAbgiYQWICStATFh5m4MreExYAWLCym4cXHFVwgoQE1aA\nmLDyFgdX8JywAsSElV04uOLKhBUgJqwsZr8K3xNWgJiwsjn7Va5OWAFiwgoQE1YW+fTgyhqAEQgr\nQExYAWLCChATVl7mxQB4jbACxISVzbgRwCiElZdYA8DrhBUgJqwAMWFlE/arjERYAWLCChATVn7k\nRgAsI6wAMWFldQ6uGI2wAsSElW/Zr8JywgoQE1ZWZb/KiIQVICasPGW/Cu8RVoCYsLIa+1VGJawA\nMWHlIftVeJ+wAsSEFSAmrKzCwRUjE1ZWYUfLyL72fgB4RRlq0zRrE1Y2dYRJ9vczCCxrEVbuVPE7\nQkS/M8+zuLIKYb2wo4cNrkpYT0YsW6ZW1iCsByekcD6uWx3UPM+iuhG/Z2rCekD+0OHchBUgJqwH\nY1qF8xNWhudWADVhBYgJK0MzrbIGYQWIeUGAIZlUWZOJleGIKmszsR7MNE2uXP3jUQi948+RCSub\nK4IoqhyZsB7QkaZWAYPlhPWgqrgKI2xPWA/sdxQfBVYw4biE9QREFM7FdSuAmLACxIQVICasADFh\nBYgJK0BMWAFiwgoQE1aAmLACxIQVICasADFhBYgJK0BMWAFiwgoQE1aAmLACxIQVICasADFhBYgJ\nK0BMWAFiwgoQE1aAmLACxIQVICasADFhBYgJK0BMWAFiwgoQE1aAmLACxIQVICasADFhBYgJK0BM\nWAFiwgoQE1aAmLACxIQVICasADFhBYgJK0Bsmud572cAuBQTK0BMWAFiwgoQE1aAmLACxIQVICas\nADFhBYgJK0BMWAFiwgoQE1aAmLACxIQVICasADFhBYgJK0BMWAFiwgoQE1aAmLACxIQVICasALH/\nASoR7QHRirclAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e526790e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = cv2.imread('img002-014.png')\n",
    "cv2.imshow('resized',i)\n",
    "cv2.waitKey(0)\n",
    "# dilation\n",
    "kernel = np.ones((3, 80), np.uint8)\n",
    "# original values 5,100\n",
    "img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "cv2.imshow('dilated', img_dilation)\n",
    "cv2.waitKey(0)\n",
    "\"\"\"i = cv2.resize(i, (28, 28))\n",
    "cv2.imshow('resized',i)\n",
    "cv2.waitKey(0)\"\"\"\n",
    "i = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('resized',i)\n",
    "cv2.waitKey(0)\n",
    "i = cv2.GaussianBlur(i, (5, 5), 0)\n",
    "cv2.imshow('resized',i)\n",
    "cv2.waitKey(0)\n",
    "#i = cv2.Canny(i, 30, 150)\n",
    "_, i = cv2.threshold(i, 200, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "cv2.imshow('Thresh',i)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "plt.imshow(i, cmap = plt.cm.gray)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
