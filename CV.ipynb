{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T02:53:52.831620Z",
     "start_time": "2019-04-28T02:53:52.688036Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method to Display Images using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T02:53:53.325713Z",
     "start_time": "2019-04-28T02:53:53.320491Z"
    }
   },
   "outputs": [],
   "source": [
    "def displayImage(image, title = 'title'):\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "quarter_height, quarter_width = height/4, width/4\n",
    "\n",
    "T = np.float32([[1, 0, quarter_width], [0, 1, quarter_height]])\n",
    "\n",
    "img_translation = cv2.warpAffine(image, T, (width, height))\n",
    "cv2.imshow('Translation', img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), 45, 1)\n",
    "\n",
    "img_translation = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "img_translation = cv2.transpose(img_translation)\n",
    "cv2.imshow('Translation', img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test.jpg')\n",
    "print(image.shape)\n",
    "cv2.imshow('Original',image)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_scaled = cv2.resize(image, None, fx = 0.5, fy = 0.5)\n",
    "cv2.imshow('Translation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_scaled = cv2.resize(image, None, fx = 2, fy = 2, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Translation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_scaled = cv2.resize(image, (300, 400), cv2.INTER_AREA)\n",
    "cv2.imshow('Translation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_scaled = cv2.resize(image, (500, 600), cv2.INTER_LANCZOS4)\n",
    "cv2.imshow('Translation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Using image pyramids\n",
    "\n",
    "smaller = cv2.pyrDown(image)\n",
    "cv2.imshow('Translation', smaller)\n",
    "cv2.waitKey()\n",
    "\n",
    "larger = cv2.pyrUp(image)\n",
    "cv2.imshow('Translation', larger)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 408\n",
      "20 122\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('./Test_Images/profile.jpg')\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "print(height, width)\n",
    "start_row, start_col = int(height * .05), int(width * .30)\n",
    "print(start_row, start_col)\n",
    "end_row, end_col = int(height * .70), int(width * .90)\n",
    "\n",
    "cropped = image[start_row:end_row, start_col:end_col]\n",
    "\n",
    "cv2.imshow('Cropped Image',cropped)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "M = np.ones(image.shape, dtype = 'uint8') * 75\n",
    "\n",
    "added = cv2.add(image, M)\n",
    "subtracted = cv2.subtract(image, M)\n",
    "\n",
    "cv2.imshow('Added', added)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('Subtracted', subtracted)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitwise operations and Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "square = np.ones((300, 300), np.uint8)\n",
    "cv2.rectangle(square, (50, 50), (250, 250), 255, -2)\n",
    "cv2.imshow('Square', square)\n",
    "cv2.waitKey()\n",
    "\n",
    "ellipse = np.ones((300, 300), np.uint8)\n",
    "cv2.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\n",
    "cv2.imshow('Ellipse', ellipse)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "And = cv2.bitwise_and(square, ellipse)\n",
    "cv2.imshow('AND', And)\n",
    "cv2.waitKey()\n",
    "\n",
    "bitwise_or = cv2.bitwise_or(square, ellipse)\n",
    "cv2.imshow('OR', bitwise_or)\n",
    "cv2.waitKey()\n",
    "\n",
    "bitwise_xor = cv2.bitwise_xor(square, ellipse)\n",
    "cv2.imshow('XOR', bitwise_xor)\n",
    "cv2.waitKey()\n",
    "\n",
    "Not = cv2.bitwise_not(square)\n",
    "cv2.imshow('NOT-square', Not)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./Test_Images/profile.jpg')\n",
    "\n",
    "kernel_sharpening = np.array([[-1, -1, -1],\n",
    "                     [-1, 9, -1],\n",
    "                     [-1, -1, -1]])\n",
    "\n",
    "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "cv2.imshow('Sharpened', sharpened)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "ret, thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary 1', thresh1)\n",
    "cv2.waitKey()\n",
    "\n",
    "ret, thresh2 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Threshold Binary 2', thresh2)\n",
    "cv2.waitKey()\n",
    "\n",
    "ret, thresh3 = cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)\n",
    "cv2.imshow('Threshold Binary 3', thresh3)\n",
    "cv2.waitKey()\n",
    "\n",
    "ret, thresh4 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)\n",
    "cv2.imshow('Threshold Binary 4', thresh4)\n",
    "cv2.waitKey()\n",
    "\n",
    "ret, thresh5 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('Threshold Binary 5', thresh5)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('test.jpg')\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "\"\"\"thresh = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "cv2.imshow('Adaptive Gaussian Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\n",
    "_,thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow('Adaptive OTSU Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\n",
    "_,thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Adaptive OTSU Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\n",
    "_,thresh = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "cv2.imshow('Adaptive OTSU Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\"\"\"\n",
    "_,thresh = cv2.threshold(image, 250, 255, cv2.THRESH_OTSU)\n",
    "cv2.imshow('Adaptive OTSU Thresholding', thresh)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilation, Erosion, Closing, Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('simpleform.jpg')\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "kernel = np.ones((4,4), np.uint8)\n",
    "\n",
    "# Removes pixels to the boundaries of object\n",
    "erosion = cv2.erode(image, kernel, iterations = 1)\n",
    "cv2.imshow('Erosion', erosion)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Adds pixels to the boundaries of object\n",
    "dilation = cv2.dilate(image, (6, 6), iterations = 1)\n",
    "cv2.imshow('Erosion', dilation)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Erosion the dilation\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Opening', opening)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Dilation then Erosion\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('Closing', closing)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('profile.jpg',0)\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "height, width = image.shape\n",
    "\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize = 5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize = 5)\n",
    "\n",
    "cv2.imshow('Sobel_X', sobel_x)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('Sobel_Y', sobel_y)\n",
    "cv2.waitKey()\n",
    "\n",
    "sobel_or = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "cv2.imshow('Sobel_X_and_Y', sobel_or)\n",
    "cv2.waitKey()\n",
    "\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "cv2.imshow('Laplacian', laplacian)\n",
    "cv2.waitKey()\n",
    "\n",
    "canny = cv2.Canny(image, 20, 170)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with shapes\n",
    "image = cv2.imread('shapes1.png')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "# Find Canny Edges\n",
    "edges = cv2.Canny(gray_blur, 30, 200)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find Contours\n",
    "_, contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Edges after contouring', edges)\n",
    "cv2.waitKey()\n",
    "\n",
    "print('Number of Contours found = ' + str(len(contours)))\n",
    "\n",
    "#contours = np.array(contours).reshape((-1,1,2)).astype(np.int32)\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 2)\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sorting Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with shapes\n",
    "image = cv2.imread('shapes1.png')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "\n",
    "original_image = image\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "edges = cv2.Canny(gray_blur, 30, 200)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find Contours\n",
    "_, contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Edges after contouring', edges)\n",
    "cv2.waitKey()\n",
    "\n",
    "print('Number of Contours found = ' + str(len(contours)))\n",
    "\n",
    "#contours = np.array(contours).reshape((-1,1,2)).astype(np.int32)\n",
    "cv2.drawContours(blank_image, contours, -1, (0,255,0), 2)\n",
    "cv2.imshow('Contours on Blank Image', blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 2)\n",
    "cv2.imshow('Contours on Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Contours by Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display area\n",
    "def contour_areas(contours):\n",
    "    # returns areas of all contours in a list\n",
    "    all_areas = []\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    \n",
    "    return all_areas\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('shapes1.png')\n",
    "original_image = image\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "edges = cv2.Canny(gray_blur, 30, 200)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find Contours\n",
    "_, contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Edges after contouring', edges)\n",
    "cv2.waitKey()\n",
    "print(contours[1])\n",
    "print('Contour Areas before Sorting')\n",
    "print(contour_areas(contours))\n",
    "\n",
    "# Sort Contours large to small\n",
    "sorted_contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\n",
    "print('Contour Areas after Sorting')\n",
    "print(contour_areas(sorted_contours))\n",
    "\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(original_image, [c], -1, (255, 0, 0), 2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('Contours by Area', original_image)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Left to Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sort left to right\n",
    "def x_cord_contour(contours):\n",
    "    \n",
    "    if cv2.contourArea(contours) > 5:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "\n",
    "def label_contour_center(image, c):\n",
    "    \n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    \n",
    "    cv2.circle(image, (cx, cy), 10, (0,125,255), -1)\n",
    "    return image\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('square-shape-activity-2.jpg')\n",
    "original_image = image.copy()\n",
    "\n",
    "for (i, c) in enumerate(contours):\n",
    "    original_image = label_contour_center(image, c)\n",
    "    \n",
    "cv2.imshow(\"Contour centres\", image)\n",
    "cv2.waitKey(0)\n",
    "# Sort by left to right\n",
    "contours_left_to_right = sorted(contours, key = x_cord_contour, reverse = False)\n",
    "\n",
    "for (i, c) in enumerate(contours_left_to_right):\n",
    "    cv2.drawContours(original_image, [c], -1, (0, 0, 255), 3)\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    cv2.putText(original_image, str(i+1), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('Left to Right Contours', original_image)\n",
    "    cv2.waitKey(0)\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    \n",
    "    # Cropping and saving each contour\n",
    "    croppped_contour = original_image[y:y + h, x:x + w]\n",
    "    image_name = \"output_shape_\" + str(i + 1) + \".jpg\"\n",
    "    print(image_name)\n",
    "    cv2.imwrite(image_name, croppped_contour)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Shape Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fdea7318228a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msorted_contours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtemplate_contour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhierarchy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_CCOMP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "template = cv2.imread('./Test_Images/A4 Copy 2x.png',0)\n",
    "cv2.imshow('Original', template)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "target = cv2.imread('./Test_Images/A4 Copy 2x.png')\n",
    "target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh1 = cv2.threshold(template, 127, 255, 0)\n",
    "ret, thresh1 = cv2.threshold(target_gray, 127, 255, 0)\n",
    "\n",
    "ret, contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "sorted_contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "\n",
    "template_contour = contours[1]\n",
    "\n",
    "ret, contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    \n",
    "    match = cv2.matchShapes(template_contour, c, 1, 0.0)\n",
    "    print(match)\n",
    "    if match < 0.15:\n",
    "        closest_contour = c\n",
    "    else:\n",
    "        closest_contour = []\n",
    "            \n",
    "cv2.drawContours(target, [closest_contour], -1, (0, 255, 0), 3)\n",
    "cv2.imshow('Output', target)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3508, 2480, 3)\n",
      "(3508, 2480, 3)\n",
      "(104, 2162)\n",
      "(104, 2162)\n",
      "-120776664.0 477414624.0 (62, 202) (196, 1488)\n",
      "Result [-120776664.0, 477414624.0, (62, 202), (196, 1488)]\n",
      "x = 196, y  = 1488 width = 2162 height = 104\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input image\n",
    "image = cv2.imread('filled_300.jpg')\n",
    "print(image.shape)\n",
    "imagecopy = image.copy()\n",
    "#image = cv2.resize(image, None, fx = 0.2, fy = 0.2)\n",
    "print(image.shape)\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Template image\n",
    "template = cv2.imread('templateform.jpg',0)\n",
    "print(template.shape)\n",
    "#template = cv2.resize(template, None, fx = 0.2, fy = 0.2)\n",
    "print(template.shape)\n",
    "cv2.imshow('Template', template)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "height = template.shape[0]\n",
    "width = template.shape[1]\n",
    "\n",
    "result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF)\n",
    "#print(result)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "print(min_val, max_val, min_loc, max_loc)\n",
    "print('Result',[min_val, max_val, min_loc, max_loc])\n",
    "# Create bounding box\n",
    "top_left = max_loc\n",
    "print('x = ' + str(max_loc[0]) + \", y  = \" + str(max_loc[1]) + ' width = ' + str(width) + ' height = ' + str(height))\n",
    "bottom_right = (top_left[0] + width, top_left[1] + height)\n",
    "#top_left[0] = float(top_left[0]) * 1.2\n",
    "#top_left[1] = float(top_left[1]) * 1.2\n",
    "top_left1 = (int(float(top_left[0]) / 0.2), int(float(top_left[1]) / 0.2))\n",
    "#bottom_right[0] = float(bottom_right[0]) * 1.2\n",
    "#bottom_right[1] = float(bottom_right[1]) * 1.2\n",
    "bottom_right1 = (int(float(bottom_right[0]) / 0.2), int(float(bottom_right[1]) / 0.2))\n",
    "cv2.rectangle(imagecopy, top_left1, bottom_right1, (0,255,0), 1)\n",
    "cv2.rectangle(image, top_left, bottom_right, (0,255,0), 1)\n",
    "# 1: x = 77, y= 48, width = 544, height = 69\n",
    "# 2: x = 85, y  = 187 width = 554 height = 62\n",
    "# 3: x = 72, y  = 514 width = 588 height = 64\n",
    "# x = 77, y  = 48 width = 544 height = 69\n",
    "# x = 385, y  = 238 width = 2721 height = 345\n",
    "cv2.imshow('Here is the match', imagecopy)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Here is the match', image)\n",
    "cv2.imwrite('testingaads.jpg',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Input image\n",
    "image = cv2.imread('./Test_Images/img_0.jpg')\n",
    "image = cv2.resize(image, (700,1000))\n",
    "print(image.shape)\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "topleft = (232,307)\n",
    "x = 232\n",
    "y = 307\n",
    "#print(topleft)\n",
    "#print(t)\n",
    "bottom_right = (x + 52, y + 121)\n",
    "cv2.rectangle(image, topleft, bottom_right, (0,255,0), 5)\n",
    "cv2.imshow('Here is the match', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oriented FAST and Rotated BRIEF (ORB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('shapes.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "orb = cv2.ORB(1000)\n",
    "\n",
    "keypoints = orb.detect(gray, None)\n",
    "\n",
    "keypoints, descriptors = orb.compute(gray, keypoints)\n",
    "print(\"Number of keypoints detected = \",len(keypoints))\n",
    "\n",
    "image = cv2.drawKeypoints(image, keypoints, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('Feature Method - ORB', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Analysis using Dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "PREDICTOR_PATH = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "class TooManyFaces(Exception):\n",
    "    pass\n",
    "\n",
    "class NoFaces(Exception):\n",
    "    pass\n",
    "\n",
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    if len(rects) > 1:\n",
    "        raise TooManyFaces\n",
    "    if len(rects) == 0:\n",
    "        raise NoFaces\n",
    "        \n",
    "    return np.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "def annotate_landmarks(im, landmarks):\n",
    "    im = im.copy()\n",
    "    \n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im, str(idx), pos, fontFace = cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale = 0.4, color = (0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color = (0, 255, 255))\n",
    "        \n",
    "    return im\n",
    "\n",
    "image = cv2.imread('profile.jpg')\n",
    "\n",
    "landmarks = get_landmarks(image)\n",
    "image_with_landmarks = annotate_landmarks(image, landmarks)\n",
    "\n",
    "cv2.imshow('Image with Landmarks',image_with_landmarks)\n",
    "cv2.imwrite('image_with_landmarks.jpg',image_with_landmarks)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('square-shape-activity-2.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, 1)\n",
    "\n",
    "ret, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours:\n",
    "    \n",
    "    approx = cv2.approxPolyDP(cnt, 0.01 * cv2.arcLength(cnt, True), True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        \n",
    "        if abs(w-h) <= 3:\n",
    "            shape_name = \"Square\"\n",
    "            \n",
    "            cv2.drawContours(image, [cnt], 0, (0, 125, 125), -1)\n",
    "            cv2.putText(image, shape_name, (cx - 5, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "    cv2.imshow('Identifying images',image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity score in two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD1CAYAAABA+A6aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBIEOAEEQ6AAQBIEOAEH8H2MRUQP5uHoSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x145b44d8ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mse(imageA, imageB):\n",
    "\t# the 'Mean Squared Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\t\n",
    "\t# return the MSE, the lower the error, the more \"similar\"\n",
    "\t# the two images are\n",
    "\treturn err\n",
    " \n",
    "def compare_images(imageA, imageB, title):\n",
    "\t# compute the mean squared error and structural similarity\n",
    "\t# index for the images\n",
    "\tm = mse(imageA, imageB)\n",
    "\ts = ssim(imageA, imageB)\n",
    "\tprint(int(m))\n",
    "\t# setup the figure\n",
    "\tfig = plt.figure(title)\n",
    "\tplt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "    \n",
    "\t# show first image\n",
    "\tax = fig.add_subplot(1, 2, 1)\n",
    "\tplt.imshow(imageA, cmap = plt.cm.gray)\n",
    "\tplt.axis(\"off\")\n",
    " \n",
    "\t# show the second image\n",
    "\tax = fig.add_subplot(1, 2, 2)\n",
    "\tplt.imshow(imageB, cmap = plt.cm.gray)\n",
    "\tplt.axis(\"off\")\n",
    " \n",
    "\t# show the images\n",
    "\tplt.show()\n",
    "    \n",
    "a = cv2.imread('1871_cnt_1.jpg')\n",
    "b = cv2.imread('1924_cnt_1.jpg')\n",
    "a = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "b = cv2.cvtColor(b, cv2.COLOR_BGR2GRAY)\n",
    "#ret, thresh1 = cv2.threshold(a, 120, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "#cv2.imshow('thresh1',thresh1)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "#ret, thresh2 = cv2.threshold(b, 120, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    \n",
    "m = compare_images(a, b, \"Original vs. Original\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trackbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-28T03:02:29.528255Z",
     "start_time": "2019-04-28T03:02:15.037907Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "nothing() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: nothing() takes 0 positional arguments but 1 was given"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "nothing() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: nothing() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "def nothing():\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('frame')\n",
    "cv2.createTrackbar('test', 'frame', 50, 255, nothing)\n",
    "cv2.createTrackbar('color/gray', 'frame', 0, 1, nothing)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    test = cv2.getTrackbarPos('test', 'frame')\n",
    "    switch = cv2.getTrackbarPos('color/gray', 'frame')\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if switch == 0:\n",
    "        thresh = frame\n",
    "    else:\n",
    "        _, thresh = cv2.threshold(frame, test, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     font = cv2.FONT_HERSHEY_COMPLEX\n",
    "#     cv2.putText(frame, str(test), (50, 150), font, 5, (0, 0, 255))\n",
    "    \n",
    "    cv2.imshow('frame', thresh)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
